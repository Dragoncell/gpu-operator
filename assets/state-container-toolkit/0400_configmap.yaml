apiVersion: v1
kind: ConfigMap
metadata:
  name: nvidia-container-toolkit-entrypoint
  namespace: "FILLED BY THE OPERATOR"
  labels:
    app: nvidia-container-toolkit-daemonset
data:
  entrypoint.sh: |-
    #!/bin/bash

    set -e

    dev_root=/run/nvidia/driver
    dev_root_ctr_path=$dev_root
    driver_root=/run/nvidia/driver
    driver_root_ctr_path=$driver_root
    if [[ -f /run/nvidia/validations/host-driver-ready ]]; then
      dev_root=${DEV_ROOT:=/}
      dev_root_ctr_path=/host
      driver_root=${DRIVER_ROOT:=/}
      driver_root_ctr_path=/host${DRIVER_ROOT}
      # update driver_root_ctr_path when custom driver and host root are the same
      if [[ "${DRIVER_ROOT}" = "${HOST_ROOT}" ]]; then
        driver_root_ctr_path=/host
      fi
    fi

    export NVIDIA_DEV_ROOT=$dev_root
    export DEV_ROOT_CTR_PATH=$dev_root_ctr_path
    export NVIDIA_DRIVER_ROOT=$driver_root
    export DRIVER_ROOT_CTR_PATH=$driver_root_ctr_path

    #
    # The below delay is a workaround for an issue affecting some versions
    # of containerd starting with 1.6.9. Staring with containerd 1.6.9 we
    # started seeing the toolkit container enter a crashloop whereby it
    # would recieve a SIGTERM shortly after restarting containerd.
    #
    # Refer to the commit message where this workaround was implemented
    # for additional details:
    #   https://github.com/NVIDIA/gpu-operator/commit/963b8dc87ed54632a7345c1fcfe842f4b7449565
    #
    sleep 5

    exec nvidia-toolkit
